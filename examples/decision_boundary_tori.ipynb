{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compatification of feature space\n",
    "Analysing decison boundaries is not an easy task, especially given the fact that the feature space is non compact.\n",
    "\n",
    "On compact spaces it is easier to work, as they a re close and bounded (Heine-Borel). \n",
    "\n",
    "We propose here a method to compactifiy the feature space $\\mathbb R^n$ to the projective space $\\mathbb RP^n$.\n",
    "\n",
    "The decision boundary, gets therefore sampled in each chart of $\\mathbb RP^n$ uniformly. When charts are put together, the resulting point cloud (defined abstractly via a dissimilarity matrix `d_final`), can be used to compute the topology of the *compactified* decision boundary.\n",
    "\n",
    "We believe that the topology so obtained can furthe be exploited for regularisation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.data import TorchDataLoader\n",
    "from gdeep.pipeline import Pipeline\n",
    "from torch import autograd  \n",
    "\n",
    "# plot\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# TDA\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.plotting import plot_diagram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build datatset\n",
    "\n",
    "We want to test our method on a 3D dataset made of 2 separate blob. We expect that the neural network decision boundary looks like and hyperplane in $\\mathbb R^3$.\n",
    "\n",
    "After compactification, we would expect to find $\\mathbb RP^2$ as final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = TorchDataLoader(name=\"DoubleTori\")\n",
    "dl_tr, dl_ts = dl.build_dataloader(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNet(\n",
      "  (layer0): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (layer1): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (layer2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "TOTAL EPOCHS  15\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Training loss: 0.785355  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 2.0%,                 Avg loss: 0.227097 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Training loss: 1.221726  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 5.0%,                 Avg loss: 0.207667 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Training loss: 0.321733  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 5.0%,                 Avg loss: 0.203786 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Training loss: 1.309438  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 5.0%,                 Avg loss: 0.200171 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Training loss: 1.310086  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 5.0%,                 Avg loss: 0.195646 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Training loss: 0.384740  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 5.0%,                 Avg loss: 0.189824 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Training loss: 0.320130  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 7.5%,                 Avg loss: 0.181827 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Training loss: 1.304887  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 10.0%,                 Avg loss: 0.172058 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Training loss: 0.317607  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 10.0%,                 Avg loss: 0.165516 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Training loss: 0.338534  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 10.0%,                 Avg loss: 0.163820 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Training loss: 0.315546  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 10.0%,                 Avg loss: 0.163739 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Training loss: 0.463842  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 10.0%,                 Avg loss: 0.163061 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Training loss: 0.317086  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 10.0%,                 Avg loss: 0.161883 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Training loss: 0.354578  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 10.0%,                 Avg loss: 0.162841 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Training loss: 0.897557  [160/160]\n",
      "Time taken for this epoch: 0s\n",
      "Validation results: \n",
      " Accuracy: 10.0%,                 Avg loss: 0.161720 \n",
      "\n",
      "Test results: \n",
      " Accuracy: 83.5%,                 Avg loss: 0.487777 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# train NN\n",
    "model = FFNet(arch=[3,10,10,2])\n",
    "print(model)\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), nn.CrossEntropyLoss(), writer)\n",
    "pipe.train(SGD, 15, batch_size=1, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-55da19da7940>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVisualiser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_data_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_decision_boundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\work\\giotto-deep\\gdeep\\visualisation\\visualiser.py\u001b[0m in \u001b[0;36mplot_data_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m                                            global_step=0)\n\u001b[0;32m     74\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             self.pipe.writer.add_embedding(features.view(max_number, -1),\n\u001b[0m\u001b[0;32m     76\u001b[0m                                            \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                                            \u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dataset'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\giotto-deep2\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36madd_embedding\u001b[1;34m(self, mat, metadata, label_img, global_step, tag, metadata_header)\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_logdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m         \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_filesystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'"
     ]
    }
   ],
   "source": [
    "from gdeep.visualisation import Visualiser\n",
    "\n",
    "vs = Visualiser(pipe)\n",
    "vs.plot_data_model()\n",
    "db, _, _ = vs.plot_decision_boundary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topology\n",
    "We chec with Giotto-tda that the topology of the decison boundary is indeed that one of $\\mathbb RP^2$, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check topology from d_final\n",
    "\n",
    "vr = VietorisRipsPersistence(collapse_edges=True, max_edge_length=1,\n",
    "                             metric=\"euclidean\", n_jobs=-1, \n",
    "                             homology_dimensions=(0,1,2))\n",
    "diag = vr.fit_transform([db])\n",
    "\n",
    "plot_diagram(diag[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower level use of the modules\n",
    "\n",
    "In this short section,. we show how to directly use the functionalities of the decision boundary calculators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.analysis.decision_boundary import QuasihyperbolicDecisionBoundaryCalculator, UniformlySampledPoint\n",
    "\n",
    "n_samples = 100\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "point_sample_generator = UniformlySampledPoint([(-2,4),(-2,2),(-2,2),(0,2*np.pi),(-1.,1.)], n_samples=n_samples)\n",
    "point_sample_tensor = torch.from_numpy(point_sample_generator()).float()\n",
    "\n",
    "phi = point_sample_tensor[:,-2].reshape(-1,1)\n",
    "theta = point_sample_tensor[:,-1].reshape(-1,1)\n",
    "theta = torch.acos(theta)\n",
    "\n",
    "y0 = torch.cat((torch.sin(theta) * torch.cos(phi),\\\n",
    "                torch.sin(theta) * torch.sin(phi),\\\n",
    "                torch.cos(theta)), -1)\n",
    "\n",
    "\n",
    "g = QuasihyperbolicDecisionBoundaryCalculator(\n",
    "            model=model,\n",
    "            initial_points=point_sample_tensor[:,:3],#torch.ones_like(y0).to(dev),#torch.distributions.uniform.Uniform(-10.,10.).sample((n_samples, 3)).to(dev),\n",
    "            initial_vectors=y0,\n",
    "            integrator=None #lambda params: torch.optim.Adam(params, )\n",
    ")\n",
    "g.step(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_points_boundary = g.get_filtered_decision_boundary(0.01).detach().cpu().numpy()\n",
    "#sample_points_boundary = g.get_decision_boundary().detach().cpu().numpy()\n",
    "\n",
    "writer.add_embedding(sample_points_boundary,\n",
    "                     tag='Decision boundary of entangled tori'\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
