{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "921c5234",
   "metadata": {},
   "source": [
    "# Basic Tutorial: BERT Models with *Giotto-Deep* and Topological Pruning\n",
    "\n",
    "#### Author: Henry Kirveslahti\n",
    "\n",
    "In this tutorial we demonstrate how to run a pre-trained BERT model with *Giotto-Deep*, as well as showcase some topological pruning methods. These pruning methods are based on the preprint *https://arxiv.org/pdf/2206.15195.pdf* by I.Perez & R.Reinauer.\n",
    "\n",
    "We will consider the NLP problem of classifying (a subset of) sentences in the *Corpus of Linguistic Acceptability (CoLA)*. To this end, we deploy a pre-trained BERT model from *HuggingFace*. We will construct the attention graph from this model, which we will use to derive Persistent Images. We then create a model that takes these persistent images as an input, and based on this model, we can compute importance scores for each of the attention heads. By only using the attention heads with high score, we can create a pruned model.\n",
    "\n",
    "\n",
    "The tutorial is organized as follows:\n",
    "\n",
    "1. Deploying the HuggingFace Model\n",
    "\n",
    "2. Fine-tuning the model using *Giotto-deep*\n",
    "\n",
    "3. Retrieving the Topological Summaries\n",
    "\n",
    "4. Training a topological model\n",
    "\n",
    "5. Pruning\n",
    "\n",
    "\n",
    "First we import some dependencies:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9373c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import wget\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "import copy\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from transformers import (\n",
    "                          BertTokenizer, \n",
    "                          BertForSequenceClassification,\n",
    "                          AdamW,\n",
    "                          BertConfig,\n",
    "                          get_linear_schedule_with_warmup)\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.optim import Adam, SparseAdam, SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.visualisation import persistence_diagrams_of_activations\n",
    "from gdeep.trainer import Trainer\n",
    "from gdeep.data import TransformingDataset\n",
    "from gdeep.data.preprocessors import TokenizerTranslation\n",
    "from gdeep.data.datasets import DatasetBuilder, FromArray, DataLoaderBuilder\n",
    "from gdeep.models import ModelExtractor\n",
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.visualisation import Visualiser\n",
    "from gdeep.search import GiottoSummaryWriter\n",
    "from gudhi.representations.vector_methods import PersistenceImage as gPI\n",
    "from gudhi import RipsComplex as gRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54449265",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the results of your models, you need to start tensorboard. All data about the model, the training, the hyperparameters... will be stored there.\n",
    "\n",
    "## How to start tensorboard\n",
    "On the terminal, move inside the `/examples` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training step to visualise all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a44e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = GiottoSummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5bbce",
   "metadata": {},
   "source": [
    "## 1. Deploying the BERT model\n",
    "\n",
    "In this section we'll just download some data and deploy a BERT model from Hugging face. This lengthy part is quite technical and independent of *giotto-deep*, so we'll just need to click through this section to get to Section 2. **The only exception is the variable**\n",
    "```\n",
    "n_sentences_to_consider\n",
    "```\n",
    "**which you could set a bit higher to get more interesting results (at a computational expense).**\n",
    "\n",
    "### 1.1 Preprocessing\n",
    "Following the pre-print, we'll adapt the pre-processing steps from *https://github.com/MohamedAteya/BERT-Fine-Tuning-Sentence-Classification-for-CoLA/blob/master/BERT_Fine_Tuning_Sentence_Classification_for_CoLA.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sentences_to_consider=300\n",
    "# Downloading the data\n",
    "print('Downloading dataset...')\n",
    "\n",
    "# The URL for the dataset zip file.\n",
    "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
    "\n",
    "# Download the file (if we haven't already)\n",
    "if not os.path.exists('./data/cola_public_1.1.zip'):\n",
    "    wget.download(url, './data/cola_public_1.1.zip')\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "if not os.path.exists('./data/cola_public/'):\n",
    "    !unzip cola_public_1.1.zip\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./data/cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "# Get the lists of sentences and their labels.\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "sentences=sentences[0:n_sentences_to_consider]\n",
    "labels=labels[0:n_sentences_to_consider]\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    encoded_sent = tokenizer.encode( sent, add_special_tokens = True)\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "\n",
    "print('Max length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813d88e",
   "metadata": {},
   "source": [
    "Next we'll define a makeshift preprocessing step. This is a verbatim copy of the padding function from *tensorflow keras*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf103c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 64\n",
    "def pad_sequences(\n",
    "    sequences,\n",
    "    maxlen=None,\n",
    "    dtype=\"int32\",\n",
    "    padding=\"pre\",\n",
    "    truncating=\"pre\",\n",
    "    value=0.0,\n",
    "):\n",
    "    if not hasattr(sequences, \"__len__\"):\n",
    "        raise ValueError(\"`sequences` must be iterable.\")\n",
    "    num_samples = len(sequences)\n",
    "\n",
    "    lengths = []\n",
    "    sample_shape = ()\n",
    "    flag = True\n",
    "    for x in sequences:\n",
    "        try:\n",
    "            lengths.append(len(x))\n",
    "            if flag and len(x):\n",
    "                sample_shape = np.asarray(x).shape[1:]\n",
    "                flag = False\n",
    "        except TypeError as e:\n",
    "            raise ValueError(\n",
    "                \"`sequences` must be a list of iterables. \"\n",
    "                f\"Found non-iterable: {str(x)}\"\n",
    "            ) from e\n",
    "\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    is_dtype_str = np.issubdtype(dtype, np.str_) or np.issubdtype(\n",
    "        dtype, np.unicode_\n",
    "    )\n",
    "    if isinstance(value, str) and dtype != object and not is_dtype_str:\n",
    "        raise ValueError(\n",
    "            f\"`dtype` {dtype} is not compatible with `value`'s type: \"\n",
    "            f\"{type(value)}\\nYou should set `dtype=object` for variable length \"\n",
    "            \"strings.\"\n",
    "        )\n",
    "\n",
    "    x = np.full((num_samples, maxlen) + sample_shape, value, dtype=dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if not len(s):\n",
    "            continue  # empty list/array was found\n",
    "        if truncating == \"pre\":\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == \"post\":\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError(f'Truncating type \"{truncating}\" not understood')\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError(\n",
    "                f\"Shape of sample {trunc.shape[1:]} of sequence at \"\n",
    "                f\"position {idx} is different from expected shape \"\n",
    "                f\"{sample_shape}\"\n",
    "            )\n",
    "\n",
    "        if padding == \"post\":\n",
    "            x[idx, : len(trunc)] = trunc\n",
    "        elif padding == \"pre\":\n",
    "            x[idx, -len(trunc) :] = trunc\n",
    "        else:\n",
    "            raise ValueError(f'Padding type \"{padding}\" not understood')\n",
    "    return x\n",
    "\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=13, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels = 2,          # TODO: WAS 4\n",
    "    output_attentions = True, \n",
    "    output_hidden_states = False\n",
    ")\n",
    "\n",
    "if(device.type=='cuda'):\n",
    "    model.cuda()\n",
    "if(device.type=='cpu'):\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee273ad8",
   "metadata": {},
   "source": [
    "## 2. Fine-Tuning the Model with *Giotto-Deep*\n",
    "\n",
    "To train a model with *giotto-deep* we'll need a) data, b) loss function, and optionally c) a performance metric. We define these below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e55497",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_builder = DataLoaderBuilder((FromArray(train_inputs, train_labels), \\\n",
    "                                FromArray(validation_inputs, validation_labels)))\n",
    "dl_tr, dl_val, _ = dl_builder.build(({\"batch_size\": 8}, {\"batch_size\": 8}))\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5bdfd",
   "metadata": {},
   "source": [
    "As per the usual *giotto-deep* paradigm, we pass these to the Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Trainer(model, (dl_tr, dl_val), loss, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581779e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with learning rate scheduler\n",
    "pipe.train(\n",
    "    Adam,\n",
    "    4,\n",
    "    False,\n",
    "    lr_scheduler=ExponentialLR,\n",
    "    scheduler_params={\"gamma\": 0.9},\n",
    "    profiling=False,\n",
    "    store_grad_layer_hist=True,\n",
    "    writer_tag=\"line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf81c2",
   "metadata": {},
   "source": [
    "## 3. Retrieving the topological summaries\n",
    "\n",
    "Now that we have trained our model and fine-tuned it, we would like to extract the topological summaries. For now we'll be interested in the attention matrices. We can retrieve them with the Model Extractor. Before diving deep into the attention matrices, let us first take a look at the inner workings of our Hugging Face model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee651a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = ModelExtractor(pipe.model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5214d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Layers\n",
    "layer_names = ex.get_layers_param().keys()\n",
    "for tmp,layer in enumerate(layer_names):\n",
    "    print(tmp,layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for computing attention masks\n",
    "def attention_mask_from_input(input):\n",
    "    mask=torch.zeros(input.shape)\n",
    "    mask[torch.nonzero(input, as_tuple=True)]=1\n",
    "    return(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8265b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp,batch=next(enumerate(dl_tr))\n",
    "b_input_ids = batch[0].to(device)\n",
    "b_input_mask=attention_mask_from_input(b_input_ids)\n",
    "b_labels = batch[1].to(device)\n",
    "outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "self_attention = ex.get_activations(b_input_ids)\n",
    "for ind_k,att in enumerate(self_attention):\n",
    "    print(ind_k,att[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd19be50",
   "metadata": {},
   "source": [
    "From the above we see that the attention matrices are in the indices 9,26,43,60,77,94,111,128,145,162,179,196. Each of these contains 12 attention heads. Next we'll loop over the train data and store these layers, with the ultimate goal of constructing the Persistent images for each.\n",
    "\n",
    "### 3.1. The Attention Matrices\n",
    "\n",
    "We will get an attention matrix for each combination of the 144 (12x12) attention heads and $n$ sentences (that is, $144n$ matrices). \n",
    "\n",
    "For the persistence function, we are using the mean aggregation scheme, which means that the only data that we need is the mean of the attention scores of edges $e_{i,j}$ and $e_{j,i}$ (and of course the vertex birth times, which are all 0). These are obtained conveniently via matrix transpose. In the code snippet below this is achieved with\n",
    "\n",
    "```\n",
    "K=0.5*(QQ+QQ.transpose(0,1,3,2))\n",
    "```\n",
    "\n",
    "Note that in the stored attention matrices, the first index runs over $L$ (layers of the network) and the second over $H$ (heads in a fixed layer). The last two indices are, of course, for the tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a8c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_attention_T=[]\n",
    "all_the_labels_T=[]\n",
    "for _,batch in enumerate(dl_tr):\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask=attention_mask_from_input(b_input_ids)\n",
    "    b_labels = batch[1].to(device)\n",
    "    self_attention = ex.get_activations(b_input_ids)\n",
    "    for i in range(len(batch[0])):\n",
    "        klist=[9,26,43,60,77,94,111,128,145,162,179,196]\n",
    "        keepers=np.where(b_input_mask[i]>0)\n",
    "        tmp2=keepers[0]\n",
    "        QQ=np.zeros((12,12,len(tmp2),len(tmp2)))\n",
    "        for ind_k,k in enumerate(klist):\n",
    "            tmp=self_attention[k][i].detach().numpy()\n",
    "            tmp3=tmp[:,tmp2,:]\n",
    "            QQ[ind_k,:,:,:]=tmp3[:,:,tmp2]\n",
    "        K=0.5*(QQ+QQ.transpose(0,1,3,2)) # Do the diag fill later as needed\n",
    "        all_the_attention_T.append(K)\n",
    "        all_the_labels_T.append(b_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32dcc4",
   "metadata": {},
   "source": [
    "### Some Sanity Checks\n",
    "Below we plot some of the attention matrices. First the raw attention matrices, then the mean aggregated ones. We'll plot these as an example, so we can later see what kind of persistent diagrams/ images these matrices produce. Note that we are not storing most of the Raw Attention Matrices, because we overwrite the QQ-array for each sample so that we only have it for the very last sample in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a09c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us plot the raw attention matrices for the last training sentence:\n",
    "fig, axs = plt.subplots(12,12)\n",
    "fig.suptitle('Raw Attention Matrices')\n",
    "\n",
    "for i in range(QQ.shape[0]):\n",
    "    for j in range(QQ.shape[1]):\n",
    "        axs[i,j].axis('off')\n",
    "        axs[i,j].imshow(QQ[i,j,:,:], cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aeb5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us plot the raw attention matrices for the last training sentence:\n",
    "fig, axs = plt.subplots(12,12)\n",
    "fig.suptitle('Mean Aggregated Matrices')\n",
    "\n",
    "for i in range(all_the_attention_T[-1].shape[0]):\n",
    "    for j in range(all_the_attention_T[-1].shape[1]):\n",
    "        axs[i,j].axis('off')\n",
    "        axs[i,j].imshow(all_the_attention_T[-1][i,j,:,:], cmap='hot', interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_attention_V=[]\n",
    "all_the_labels_V=[]\n",
    "for _,batch in enumerate(dl_val):\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask=attention_mask_from_input(b_input_ids)\n",
    "    b_labels = batch[1].to(device)\n",
    "    self_attention = ex.get_activations(b_input_ids)\n",
    "    for i in range(len(batch[0])):\n",
    "        klist=[9,26,43,60,77,94,111,128,145,162,179,196]\n",
    "        keepers=np.where(b_input_mask[i]>0)\n",
    "        tmp2=keepers[0]\n",
    "        QQ=np.zeros((12,12,len(tmp2),len(tmp2)))\n",
    "        for ind_k,k in enumerate(klist):\n",
    "            tmp=self_attention[k][i].detach().numpy()\n",
    "            tmp3=tmp[:,tmp2,:]\n",
    "            QQ[ind_k,:,:,:]=tmp3[:,:,tmp2]\n",
    "        K=0.5*(QQ+QQ.transpose(0,1,3,2)) # Do the diag fill later as needed\n",
    "        all_the_attention_V.append(K)\n",
    "        all_the_labels_V.append(b_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5deff10",
   "metadata": {},
   "source": [
    "### 3.2 Persistence Diagrams\n",
    "\n",
    "Next we'll compute the Persistent diagrams. We'll use *gudhi* library for this. The specifications are as in the preprint:\n",
    "1. The filtration value for the undirected edge $(i,j)$ is $1-f(e_{ij},e_{ji})$, where $f$ is the mean of directed edges (See Section 3.2)\n",
    "2. All the vertices are born at 0; (That is: ```np.fill_diagonal(dm,0)```)\n",
    "3. All the essential features are set to die at 1; (```d0[np.isinf(d0)] = 1; d1[np.isinf(d1)] = 1```)\n",
    "4. The maximum dimension is 1. (```max_dimension=1; persistence_dim_max=True)```)\n",
    "\n",
    "See Figure 3 in the preprint for illustrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd3e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagramsh0_train=[]\n",
    "diagramsh1_train=[]\n",
    "for i in range(len(all_the_attention_T)):\n",
    "    graph=all_the_attention_T[i]\n",
    "    for j in range(graph.shape[0]):\n",
    "        for k in range(graph.shape[1]):\n",
    "            dm=1-graph[j,k,:,:]\n",
    "            np.fill_diagonal(dm,0)\n",
    "            gudhiC=gRC(distance_matrix=dm)\n",
    "            simplex_tree = gudhiC.create_simplex_tree(max_dimension=1)\n",
    "            diag = simplex_tree.persistence(min_persistence=0.0001,persistence_dim_max=True)\n",
    "            d0=simplex_tree.persistence_intervals_in_dimension(0)\n",
    "            d1=simplex_tree.persistence_intervals_in_dimension(1)\n",
    "            d0[np.isinf(d0)] = 1\n",
    "            d1[np.isinf(d1)] = 1\n",
    "            diagramsh0_train.append(d0)\n",
    "            diagramsh1_train.append(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7042763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And same for the validation\n",
    "diagramsh0_valid=[]\n",
    "diagramsh1_valid=[]\n",
    "for i in range(len(all_the_attention_V)):\n",
    "    graph=all_the_attention_V[i]\n",
    "    for j in range(graph.shape[0]):\n",
    "        for k in range(graph.shape[1]):\n",
    "            dm=1-graph[j,k,:,:]\n",
    "            np.fill_diagonal(dm,0)\n",
    "            gudhiC=gRC(distance_matrix=dm)\n",
    "            simplex_tree = gudhiC.create_simplex_tree(max_dimension=1)\n",
    "            diag = simplex_tree.persistence(min_persistence=0.0001,persistence_dim_max=True)\n",
    "            d0=simplex_tree.persistence_intervals_in_dimension(0)\n",
    "            d1=simplex_tree.persistence_intervals_in_dimension(1)\n",
    "            d0[np.isinf(d0)] = 1\n",
    "            d1[np.isinf(d1)] = 1\n",
    "            diagramsh0_valid.append(d0)\n",
    "            diagramsh1_valid.append(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb8d75",
   "metadata": {},
   "source": [
    "### Some Sanity Checks\n",
    "Let's plot the Persistent diagrams for the attention matrices we checked earlier. Here we plot all the 144 diagrams: At such they are quite difficult to read. Because these change from run to run, you should hand pick some for closer inspection. Take a look at the matrices above, select a few that look different and look at the corresponding diagrams to get intuition how the diagrams turn out to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_d0=diagramsh0_train[-144:]\n",
    "tmp_d1=diagramsh1_train[-144:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.lines as mlines\n",
    "fig, axs = plt.subplots(12,12)\n",
    "fig.suptitle('Persistence Diagrams')\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        ind=12*i+j\n",
    "        axs[i,j].axis('off')\n",
    "        axs[i,j].scatter(tmp_d0[ind][:,0],tmp_d0[ind][:,1],c='blue', s=0.01)\n",
    "        axs[i,j].scatter(tmp_d1[ind][:,0],tmp_d1[ind][:,1],c='red', s=0.01)\n",
    "        line = mlines.Line2D([0, 1], [0, 1], color='black', linewidth=0.05)\n",
    "        axs[i,j].add_line(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4080f4",
   "metadata": {},
   "source": [
    "### 3.3 Persistent Images\n",
    "\n",
    "We can now compute the Persistent Images. The parameters are adapted from the preprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pers0=gPI(bandwidth=0.1, weight=lambda x: 1,im_range=[0,0.01,0,1], resolution=[5,50])\n",
    "PI0t=pers0.fit_transform(diagramsh0_train)\n",
    "PI0v=pers0.fit_transform(diagramsh0_valid)\n",
    "pers1=gPI(bandwidth=0.1, weight=lambda x: 1,im_range=[0,1,0.99,1], resolution=[50,5])\n",
    "PI1t=pers1.fit_transform(diagramsh1_train)\n",
    "PI1v=pers1.fit_transform(diagramsh1_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10529627",
   "metadata": {},
   "source": [
    "The data from the persistent Image computations is a list, which is not fantastic for bookkeeping. We'll convert the data into proper images of size 5x50 with 288 channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For the sake of transparency, we'll reshape our Persistent Images to size\n",
    "## (n, 288, 5 ,50), where n is the sample size\n",
    "## the second dimension is the attention heads concatenated with homology dimension\n",
    "## This is the same setup as in the preprint, and allows for a direct application of a convolutional neural network\n",
    "## (note that the simple model in this notebook doesn't make use of this structure)\n",
    "\n",
    "trainh0=PI0t.reshape(-1,144,250)\n",
    "trainh0=trainh0.reshape(-1,144,50,5)\n",
    "trainh0=trainh0.transpose(0,1,3,2)\n",
    "#the original trainh0=trainh0.reshape(-1,144,5,50)\n",
    "\n",
    "validh0=PI0v.reshape(-1,144,250)\n",
    "validh0=validh0.reshape(-1,144,50,5)\n",
    "validh0=validh0.transpose(0,1,3,2)\n",
    "#validh0=validh0.reshape(-1,144,5,50)\n",
    "\n",
    "\n",
    "trainh1=PI1t.reshape(-1,144,250)\n",
    "trainh1=trainh1.reshape(-1,144,50,5)\n",
    "trainh1=trainh1.transpose(0,1,3,2)\n",
    "\n",
    "validh1=PI1v.reshape(-1,144,250)\n",
    "validh1=validh1.reshape(-1,144,50,5)\n",
    "validh1=validh1.transpose(0,1,3,2)\n",
    "\n",
    "test=np.concatenate([trainh0,trainh1],axis=1)\n",
    "test2=np.concatenate([validh0,validh1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8284f7",
   "metadata": {},
   "source": [
    "### Some Sanity Checks\n",
    "Let's have a look at the persistent images for the matrices we saw earlier. Again, you should investigate a specific image to get a better idea of what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_im0=test[-1,:144,:,:] #H0\n",
    "tmp_im1=test[-1,144:,:,:] #H1\n",
    "tmp_im0=tmp_im0.transpose(0,2,1)\n",
    "tmp_im1=tmp_im1.transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "fig, axs = plt.subplots(12,12)\n",
    "fig.suptitle('Images H0')\n",
    "\n",
    "for k in range(tmp_im0.shape[0]):\n",
    "    j=math.floor(k/12)\n",
    "    i=k%12\n",
    "    axs[i,j].axis('off')\n",
    "    axs[i,j].imshow(tmp_im0[k,:,:], cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca81e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "fig, axs = plt.subplots(12,12)\n",
    "fig.suptitle('Images H1')\n",
    "\n",
    "for k in range(tmp_im1.shape[0]):\n",
    "    j=math.floor(k/12)\n",
    "    i=k%12\n",
    "    axs[i,j].axis('off')\n",
    "    axs[i,j].imshow(tmp_im1[k,:,:], cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718fb675",
   "metadata": {},
   "source": [
    "### A hand-picked example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=0\n",
    "H=3\n",
    "k=12*L+H\n",
    "\n",
    "plt.imshow(QQ[L,H,:,:], cmap='hot', interpolation='nearest')\n",
    "plt.title(\"Raw Attention Matrix\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(all_the_attention_T[-1][L,H,:,:], cmap='hot', interpolation='nearest')\n",
    "plt.title(\"The Mean\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4a680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The persistent diagram from the matrix above:\n",
    "plt.scatter(tmp_d0[k][:,0],tmp_d0[k][:,1],c='blue', s=3)\n",
    "plt.scatter(tmp_d1[k][:,0],tmp_d1[k][:,1],c='red', s=3)\n",
    "plt.plot([0, 1], c='black')\n",
    "plt.title(\"Resulting Persistent Diagram\")\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.suptitle(\"Persistent Images\")\n",
    "axs[0].imshow(tmp_im0[k,:,:], cmap='hot', interpolation='nearest')\n",
    "axs[1].imshow(tmp_im1[k,:,:], cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5183526",
   "metadata": {},
   "source": [
    "## 4. Training a topological model\n",
    "We'll train a super simple model based on our topological summaries. This follows the usual *giotto-deep* recipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_builder2 = DataLoaderBuilder((FromArray(test, train_labels), FromArray(test2, validation_labels)))\n",
    "dl_tr2, dl_val2, _ = dl_builder2.build(({\"batch_size\": 8}, {\"batch_size\": 8}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(288*50*5,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(net.parameters(), lr=0.000067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Trainer(net, (dl_tr2, dl_val2), criterion, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18114eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.train(\n",
    "    Adam,\n",
    "    20,\n",
    "    False,\n",
    "    lr_scheduler=ExponentialLR,\n",
    "    scheduler_params={\"gamma\": 0.9},\n",
    "    profiling=False,\n",
    "    store_grad_layer_hist=True,\n",
    "    writer_tag=\"line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af94eb4",
   "metadata": {},
   "source": [
    "## 5. Pruning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2400bf6",
   "metadata": {},
   "source": [
    "The topological model we just defined is quite transparent in that we can easily define importance metrics for the attention heads (in essence, these are just features we fed to the model). We'll follow the importance metrics used in the preprint, namely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1=torch.FloatTensor(test)\n",
    "train_labels=torch.FloatTensor(train_labels)\n",
    "validation_labels=torch.FloatTensor(validation_labels)\n",
    "train_labels = train_labels.type(torch.LongTensor)\n",
    "validation_labels = validation_labels.type(torch.LongTensor)\n",
    "batch_size=3\n",
    "tmp2=torch.FloatTensor(test2)\n",
    "tmp2.requires_grad=True\n",
    "ds1 = TensorDataset(tmp1, train_labels)\n",
    "ds2 = TensorDataset(tmp2, validation_labels)\n",
    "trainloader = torch.utils.data.DataLoader(ds1, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(ds2, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute some gradients\n",
    "imageset=trainloader.dataset[0:500][0]\n",
    "target_label=trainloader.dataset[0:500][1]\n",
    "a = torch.autograd.Variable(imageset)\n",
    "a.requires_grad=True\n",
    "outputs=net(a)\n",
    "target_label\n",
    "loss = criterion(outputs,target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930573dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_grad = torch.autograd.grad(loss, a, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=np.sum(abs(a_grad[0].detach().cpu().numpy()), axis=(0,2,3))\n",
    "tmp2=tmp[0:144]+tmp[144:] # Average over hom.dim (H0+H1)\n",
    "#tmp2\n",
    "tmp3=tmp2.reshape(12,12) # Unpack for plotting\n",
    "plt.imshow(tmp3, cmap='hot', interpolation='nearest')\n",
    "plt.ylabel('L (depth)')\n",
    "plt.xlabel('H (attention head)')\n",
    "plt.title('Importance Scores for Attention heads')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48070ab0",
   "metadata": {},
   "source": [
    "We can now select the most impactful however many heads we want. In the code below we take the top 100. We'll stick to the simple model we used earlier, so you only need to change\n",
    "```\n",
    "heads_to_keep\n",
    "```\n",
    "in the code chunk below to select however many heads you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73848873",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads_to_keep=100\n",
    "pruned_indices=np.argsort(tmp2)[-heads_to_keep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e8dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainprunedh0=trainh0[:,pruned_indices,:,:]\n",
    "trainprunedh1=trainh1[:,pruned_indices,:,:]\n",
    "validprunedh0=validh0[:,pruned_indices,:,:]\n",
    "validprunedh1=validh1[:,pruned_indices,:,:]\n",
    "\n",
    "test=np.concatenate([trainprunedh0,trainprunedh1],axis=1)\n",
    "test2=np.concatenate([validprunedh0,validprunedh0],axis=1)\n",
    "test= test.astype(np.float32)\n",
    "test2= test2.astype(np.float32)\n",
    "tmp1=torch.FloatTensor(test)\n",
    "tmp2=torch.FloatTensor(test2)\n",
    "tmp2.requires_grad=True\n",
    "ds1 = TensorDataset(tmp1, train_labels)\n",
    "ds2 = TensorDataset(tmp2, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(ds1, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(ds2, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_builder2 = DataLoaderBuilder((FromArray(test, train_labels), FromArray(test2, validation_labels)))\n",
    "dl_tr2, dl_val2, _ = dl_builder2.build(({\"batch_size\": 8}, {\"batch_size\": 8}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(2*heads_to_keep*50*5,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(net.parameters(), lr=0.000067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421526f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Trainer(net, (dl_tr2, dl_val2), criterion, writer)\n",
    "# train the model with learning rate scheduler\n",
    "pipe2.train(\n",
    "    Adam,\n",
    "    20,\n",
    "    False,\n",
    "    lr_scheduler=ExponentialLR,\n",
    "    scheduler_params={\"gamma\": 0.9},\n",
    "    profiling=False,\n",
    "    store_grad_layer_hist=True,\n",
    "    writer_tag=\"line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bdfa4b",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f464b",
   "metadata": {},
   "source": [
    "In this tutorial, we used *giotto-deep* to\n",
    "1. Fit an off the shelf Huggingface model;\n",
    "2. Fine tune it;\n",
    "3. Extract its inner workings to;\n",
    "4. construct a pruned model.\n",
    "\n",
    "Depending on the choices made along the way, the pruned model may be anything from strong to terrible. To increase performance, you may\n",
    "\n",
    "1. Add more data (remember this notebook is heavily subsampled);\n",
    "2. Spend more time fine-tuning the BERT; \n",
    "3. Fit more complicated models;\n",
    "4. Optimize the parameters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
