{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tutorial: image data\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "This short tutorial provides you with the basic functioning of *giotto-deep* API.\n",
    "\n",
    "The main steps of the tutorial are the following:\n",
    " 1. creation of a dataset\n",
    " 2. creation of a model\n",
    " 3. define metrics and losses\n",
    " 4. run benchmarks\n",
    " 5. visualise results interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "\n",
    "from gdeep.visualisation import  persistence_diagrams_of_activations\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gdeep.data import TorchDataLoader\n",
    "\n",
    "\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from gtda.plotting import plot_betti_surfaces\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the reuslts of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/example` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training to see all the visualisation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10240\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "20\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "dl = TorchDataLoader(name=\"CIFAR10\")\n",
    "train_indices = []\n",
    "for i in range(10240):\n",
    "    train_indices.append(i)\n",
    "\n",
    "print(len(train_indices))\n",
    "dl_tr, dl_temp = dl.build_dataloader(batch_size=512, sampler=SubsetRandomSampler(train_indices))\n",
    "\n",
    "print(len(dl_tr))\n",
    "\n",
    "test_indices = []\n",
    "for i in range(3072):\n",
    "    test_indices.append(i)\n",
    "\n",
    "dl_ts, dl_temp = dl.build_dataloader(batch_size=512, sampler=SubsetRandomSampler(test_indices))\n",
    "\n",
    "dl_val = dl_ts\n",
    "\n",
    "print(len(dl_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from gdeep.pipeline import Pipeline\n",
    "\n",
    "model = nn.Sequential(models.resnet18(pretrained=True), nn.Linear(1000,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "TOTAL EPOCHS  1\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\giotto-deep2\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.575110  [20/20]\n",
      "Time taken for this epoch: 71s\n",
      "Validation results: \n",
      " Accuracy: 3.2%,                 Avg loss: 0.000159 \n",
      "\n",
      "Test results: \n",
      " Accuracy: 3.3%,                 Avg loss: 0.000159 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD, Adam, RMSprop\n",
    "from gdeep.search import gridsearch\n",
    "\n",
    "# print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "# pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer, True, \"loss\", 5)\n",
    "pipe = Pipeline(model, [dl_tr, dl_val, dl_ts], loss_fn, writer)\n",
    "# pipe = Pipeline(model, [dl_tr, dl_ts], loss_fn, writer)\n",
    "\n",
    "# search = gridsearch.Gridsearch(pipe, \"loss\", 5)\n",
    "# search.search([SGD, Adam], 1, lr=[0.001, 0.01])\n",
    "\n",
    "# train the model\n",
    "pipe.train(SGD, 1, cross_validation = True, batch_size = 512, lr=0.01)\n",
    "# pipe.train([SGD, Adam], 1, lr=[0.001, 0.01])\n",
    "# pipe.train([SGD, Adam], 1, lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-29 15:09:39,249]\u001b[0m A new study created in memory with name: no-name-45626f93-f233-4ba7-a40e-356dfcc853cb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\giotto-deep2\\lib\\site-packages\\optuna\\distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "d:\\anaconda3\\envs\\giotto-deep2\\lib\\site-packages\\optuna\\distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.098912  [20/20]\n",
      "Time taken for this epoch: 72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-29 15:10:53,831]\u001b[0m Trial 0 finished with value: 1.0989115238189697 and parameters: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.0015958022260856906}. Best is trial 0 with value: 1.0989115238189697.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results: \n",
      " Accuracy: 4.1%,                 Avg loss: 0.000125 \n",
      "\n",
      "Done!\n",
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  1.0989115238189697\n",
      "  Params: \n",
      "    optimizer: <class 'torch.optim.adam.Adam'>\n",
      "    lr: 0.0015958022260856906\n"
     ]
    }
   ],
   "source": [
    "from gdeep.search.gridsearch import Gridsearch\n",
    "from torch.optim import SGD, Adam, RMSprop\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "pipe = Pipeline(model, [dl_tr, dl_val, dl_ts], loss_fn, writer)\n",
    "# pipe = Pipeline([model1, model2, ...], [[dl_tr, dl_val, dl_ts], [dl_tr2, dl_val2, dl_ts2], ...], loss_fn, writer)\n",
    "\n",
    "search = Gridsearch(pipe, \"loss\", 1)\n",
    "search.start([SGD, Adam], 1, lr=[0.001, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch with multiple pipelines (models/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gdeep.search.gridsearch import Gridsearch\n",
    "\n",
    "# pipe1 = Pipeline(model1, [dl_tr, dl_ts, dl_ts], loss_fn, writer)\n",
    "# pipe2 = Pipeline(model2, [dl_tr, dl_ts, dl_ts], loss_fn, writer)\n",
    "\n",
    "# search1 = Gridsearch(pipe1, \"loss\", 2)\n",
    "# search1.search([SGD, Adam], 1, lr=[0.001, 0.01])\n",
    "\n",
    "# search2 = Gridsearch(pipe1, \"loss\", 2)\n",
    "# search2.search([SGD, Adam], 1, lr=[0.001, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking a single model on multiple datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CIFAR10_10000\n"
     ]
    }
   ],
   "source": [
    "dataloaders_dicts = []\n",
    "dl = TorchDataLoader(name=\"CIFAR10\")\n",
    "train_indices = []\n",
    "for i in range(5120):\n",
    "    train_indices.append(i)\n",
    "\n",
    "dl_tr, dl_temp = dl.build_dataloader(batch_size=1024, sampler=SubsetRandomSampler(train_indices))\n",
    "\n",
    "test_indices = []\n",
    "for i in range(1024):\n",
    "    test_indices.append(i)\n",
    "\n",
    "dl_ts, dl_temp = dl.build_dataloader(batch_size=1024, sampler=SubsetRandomSampler(test_indices))\n",
    "\n",
    "temp_dict = {}\n",
    "temp_dict[\"name\"] = \"CIFAR10_5000\"\n",
    "temp_dict[\"dataloaders\"] = (dl_tr, dl_ts)\n",
    "\n",
    "dataloaders_dicts.append(temp_dict)\n",
    "\n",
    "\n",
    "train_indices = []\n",
    "for i in range(10240):\n",
    "    train_indices.append(i)\n",
    "\n",
    "dl_tr, dl_temp = dl.build_dataloader(batch_size=1024, sampler=SubsetRandomSampler(train_indices))\n",
    "\n",
    "test_indices = []\n",
    "for i in range(2048):\n",
    "    test_indices.append(i)\n",
    "\n",
    "dl_ts, dl_temp = dl.build_dataloader(batch_size=1024, sampler=SubsetRandomSampler(test_indices))\n",
    "\n",
    "temp_dict = {}\n",
    "temp_dict[\"name\"] = \"CIFAR10_10000\"\n",
    "temp_dict[\"dataloaders\"] = (dl_tr, dl_ts)\n",
    "\n",
    "dataloaders_dicts.append(temp_dict)\n",
    "\n",
    "print(dataloaders_dicts[1][\"name\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gdeep.pipeline import benchmark\n",
    "\n",
    "# bench = benchmark.Benchmark(writer)\n",
    "\n",
    "# bench.benchmark_model(model, dataloaders_dicts, loss_fn, SGD, 1, 0.01)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking a single dataset on multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dicts = []\n",
    "\n",
    "model = nn.Sequential(models.resnet18(pretrained=True), nn.Linear(1000,10))\n",
    "temp_dict = {}\n",
    "temp_dict[\"name\"] = \"resnet18\"\n",
    "temp_dict[\"model\"] = model\n",
    "\n",
    "models_dicts.append(temp_dict)\n",
    "\n",
    "model = nn.Sequential(models.vgg16(pretrained=True), nn.Linear(1000,10))\n",
    "temp_dict = {}\n",
    "temp_dict[\"name\"] = \"vgg16\"\n",
    "temp_dict[\"model\"] = model\n",
    "\n",
    "models_dicts.append(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bench = benchmark.Benchmark(writer)\n",
    "\n",
    "# bench.benchmark_data(model_dicts, (dl_tr, dl_ts), loss_fn, SGD, 1, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gdeep.search.benchmark import Benchmark\n",
    "# from torch.optim import SGD, Adam, RMSprop\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# bench = Benchmark(writer)\n",
    "\n",
    "# bench.benchmark(models_dicts, dataloaders_dicts, loss_fn, optimizer = SGD, epochs = 1, learning_rate = 0.01, batch_size = 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking + Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-29 15:11:02,119]\u001b[0m A new study created in memory with name: no-name-beb19209-347e-4912-b7e0-7c0854c3ab69\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Performing Gridsearch on Dataset: CIFAR10_5000, Model: resnet18\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Training loss: 2.562519  [ 4/ 4]\n",
      "Time taken for this epoch: 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-29 15:11:16,997]\u001b[0m Trial 0 finished with value: 2.5625193119049072 and parameters: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.0012954971263344564}. Best is trial 0 with value: 2.5625193119049072.\u001b[0m\n",
      "\u001b[32m[I 2021-07-29 15:11:16,998]\u001b[0m A new study created in memory with name: no-name-d5ad4273-92fa-421b-99c6-b164fe15e183\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results: \n",
      " Accuracy: 0.4%,                 Avg loss: 0.000041 \n",
      "\n",
      "Done!\n",
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  2.5625193119049072\n",
      "  Params: \n",
      "    optimizer: <class 'torch.optim.adam.Adam'>\n",
      "    lr: 0.0012954971263344564\n",
      "****************************************\n",
      "Performing Gridsearch on Dataset: CIFAR10_5000, Model: vgg16\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Training loss: 2.516128  [ 4/ 4]\n",
      "Time taken for this epoch: 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-29 15:11:52,099]\u001b[0m Trial 0 finished with value: 2.5161280632019043 and parameters: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.0012724480460049447}. Best is trial 0 with value: 2.5161280632019043.\u001b[0m\n",
      "\u001b[32m[I 2021-07-29 15:11:52,100]\u001b[0m A new study created in memory with name: no-name-d398577d-a2a3-4484-bc46-c20d1201e266\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results: \n",
      " Accuracy: 0.1%,                 Avg loss: 0.000048 \n",
      "\n",
      "Done!\n",
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  2.5161280632019043\n",
      "  Params: \n",
      "    optimizer: <class 'torch.optim.adam.Adam'>\n",
      "    lr: 0.0012724480460049447\n",
      "****************************************\n",
      "Performing Gridsearch on Dataset: CIFAR10_10000, Model: resnet18\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Training loss: 2.091243  [ 8/ 8]\n",
      "Time taken for this epoch: 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-29 15:12:21,248]\u001b[0m Trial 0 finished with value: 2.091243028640747 and parameters: {'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.002391287633739927}. Best is trial 0 with value: 2.091243028640747.\u001b[0m\n",
      "\u001b[32m[I 2021-07-29 15:12:21,249]\u001b[0m A new study created in memory with name: no-name-392a60aa-dc21-4f88-9fd5-5ee073391f56\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results: \n",
      " Accuracy: 0.7%,                 Avg loss: 0.000078 \n",
      "\n",
      "Done!\n",
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  2.091243028640747\n",
      "  Params: \n",
      "    optimizer: <class 'torch.optim.adam.Adam'>\n",
      "    lr: 0.002391287633739927\n",
      "****************************************\n",
      "Performing Gridsearch on Dataset: CIFAR10_10000, Model: vgg16\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Training loss: 2.323467  [ 8/ 8]\n",
      "Time taken for this epoch: 60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-29 15:13:24,642]\u001b[0m Trial 0 finished with value: 2.3234665393829346 and parameters: {'optimizer': <class 'torch.optim.sgd.SGD'>, 'lr': 0.003507416933614802}. Best is trial 0 with value: 2.3234665393829346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results: \n",
      " Accuracy: 0.2%,                 Avg loss: 0.000093 \n",
      "\n",
      "Done!\n",
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  2.3234665393829346\n",
      "  Params: \n",
      "    optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "    lr: 0.003507416933614802\n"
     ]
    }
   ],
   "source": [
    "from gdeep.search.benchmark import Benchmark\n",
    "from gdeep.search.gridsearch import Gridsearch\n",
    "from torch.optim import SGD, Adam, RMSprop\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "bench = Benchmark(models_dicts, dataloaders_dicts, loss_fn, writer)\n",
    "\n",
    "search = Gridsearch(bench, \"loss\", 1)\n",
    "search.start([SGD, Adam], 1, 512, lr=[0.001, 0.01])\n",
    "\n",
    "# bench.benchmark(optimizer = [SGD,Adam], epochs = 1, learning_rate = [0.001,0.01], batch_size = 1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
