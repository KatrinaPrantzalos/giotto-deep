{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6213f4-bb90-4f03-8bc0-51c96bac8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3acaa0-f904-4ac2-83de-7094a084a99c",
   "metadata": {},
   "source": [
    "Run the redis server:\n",
    "`redis-server`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f58a8-1244-4174-b4a4-a01b9466b372",
   "metadata": {},
   "source": [
    "make sure mysql runs\n",
    "\n",
    "```\n",
    "docker run --name=user_mysql_1 --env=\"MYSQL_ROOT_PASSWORD=root_password\" -p 3306:3306 -d mysql:latest\n",
    "```\n",
    "\n",
    "make sure redis runs\n",
    "\n",
    "```\n",
    "redis-server\n",
    "```\n",
    "\n",
    "\n",
    "connect to mysql each redis worker\n",
    "\n",
    "\n",
    "**addendum**: to stop \n",
    "\n",
    "```\n",
    "/usr/local/bin/mysql.server stop\n",
    "\n",
    "ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'root_password';\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d59a5e-120c-4846-8c78-428ff8e1dd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TPUs...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Job('29cb06aa-9ab2-4f48-8dab-49a0f37fdc11', enqueued_at=datetime.datetime(2022, 6, 21, 9, 22, 27, 920082))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "from redis import Redis\n",
    "from rq import Queue\n",
    "from rq import Retry\n",
    "\n",
    "# needed\n",
    "from parallel_hpo import connect_to_mysql, run_hpo_parallel, test_fnc\n",
    "\n",
    "redis = Redis()\n",
    "q = Queue(connection=redis)\n",
    "job = q.enqueue(test_fnc, \"hello!\", retry=Retry(max=3))\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c46a02-9e63-4b5d-aeba-6ef57928d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to wait a bit before being able to see the result\n",
    "job.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee36233-e684-4c20-858d-fbdfc226c6b1",
   "metadata": {},
   "source": [
    "So far you have enqueued the jobs: now you have to start the workers so that the jobs can be crunched!\n",
    "\n",
    "```\n",
    "rq worker high default low\n",
    "```\n",
    "\n",
    "You can set up multiple workers to have the HPO run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcad356-9a8c-4eb5-ac5a-9e54ac234298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.search import HyperParameterOptimization\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from gtda.diagrams import BettiCurve\n",
    "from gtda.plotting import plot_betti_surfaces\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "# RQ\n",
    "from redis import Redis\n",
    "from rq import Queue, Connection\n",
    "from rq import Retry\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.models import ModelExtractor\n",
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.utility.optimisation import SAMOptimizer\n",
    "from gdeep.visualisation import persistence_diagrams_of_activations\n",
    "from gdeep.trainer import Trainer\n",
    "from gdeep.data.datasets import DatasetBuilder, DataLoaderBuilder\n",
    "from gdeep.visualisation import Visualiser\n",
    "from gdeep.utility import DEVICE\n",
    "from gdeep.search import GiottoSummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b8c1c-c2ba-43df-be94-03781e09e7e7",
   "metadata": {},
   "source": [
    "# Enqueuing the jobs\n",
    "\n",
    "In the next section we enqueue te HPO and make sure that the workers are actively cruching the jobs! If more tan one worker is active, the job gets distributed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3becca4e-2218-4c51-86fe-38e2374640c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection.MySQLConnection object at 0x7fe7365ae6d0>\n",
      "('example',)\n",
      "('information_schema',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('sys',)\n",
      "DB connected\n",
      "jobs enqueued\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# constants\n",
    "USER = \"root\"\n",
    "HOST = \"127.0.0.1\"\n",
    "PSW = \"root_password\"\n",
    "\n",
    "# connect to mysql\n",
    "connect_to_mysql(USER, PSW, HOST)\n",
    "print(\"DB connected\")\n",
    "\n",
    "# enqueue hpo jobs\n",
    "hpo_job = q.enqueue(run_hpo_parallel, args=(USER, PSW, HOST), retry=Retry(max=3))\n",
    "hpo_job2 = q.enqueue(run_hpo_parallel, args=(USER, PSW, HOST), retry=Retry(max=3))\n",
    "print(\"jobs enqueued\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87500989-bd53-4607-a5ba-9aea0ef168b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
